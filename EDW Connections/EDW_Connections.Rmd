---
title: "SQL Server and R"
author: "Rollie Parrish"
date: "October 28, 2015"
output:
  revealjs::revealjs_presentation:
    theme: moon
    transition: slide
    highlight: zenburn
    fig_caption: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(readr)
library(data.table)

```

## How to get data from SQL Server into R

1. Import .csv files
2. SQL query using ODBC
3. edwSQL() - a convenience function


## .csv files

- Export .csv files via Toad, SSMS, etc.
- Import using `read.csv`, `read_csv`, or `fread`.
 

- Pros

    - Simple
   
 - Cons  

    - Copies of data may be stored in various locations
    - Must be re-exported when data is updated

## .csv examples

```{r csv, echo = TRUE, cache = TRUE}
# flight.csv - 
# Flight data from NYC in 2013
# a 25 MB file with 336K+ rows, and 16 columns
# Source: nycflights13 from the dplyr package

# Base R
system.time(read.csv("Data/flight.csv"))

# readr package
system.time(readr::read_csv("Data/flight.csv"))

# data.tables package
system.time(data.table::fread("Data/flight.csv"))

```


## Direct connection using ODBC

- Pros
    - Streamlines workflow / automation
    - Data can remain in souce databases

- Cons
    - Requires database access
    - Need basic SQL familiarity (select, join, where, etc.)



## RODBC package

Uses a DSN or a "connection string" 

```{r rodbc, echo = TRUE, eval = FALSE}
library(RODBC)

# Package Vignette (pdf file) with more information
RShowDoc("RODBC", package="RODBC")

# A blank username & password defaults to 
# a "trusted connection" using the user's Windows credentials

# Using DSN
myconn <- odbcConnect("EDWDBDev", uid="", pwd="")

# Using connection string
myconn <- odbcDriverConnect(connection = "Driver=SQL Server;Server=EDWDBDev;Database=ProvidenceEpic")

# this will load an entire table. 
entire_table <- sqlFetch(myconn, "name_of_table") 

# this just loads the query results
mydata <- sqlQuery(myconn, "SELECT TOP 100 * FROM name_of_table") 

# must close the connection when done
close(myconn)

```


## edwSQL() 

A convenience wrapper for RODBC 

- single line of code to load data 
- supports the use of separate .sql files 
    - Useful for more complex SQL queries
    - Multiple data sources
    - Collaboration/reuse of existing SQL queries
- DSN is not required  
    - loads database drivers directly
    - more portable code



## edwSQL()
```{r edwSQL, eval = FALSE, echo = TRUE}
library(RPamisc)

# This will load a .sql file, open a connection to 
# the named resource, which is just an alias for a database connection
# then close the connection
# 
# uses system credentials, so only works if user has database access

mydata <- edwSQL(sql = "../SQL/example_query.sql", resource = "Trantor")



```


## edwSQL()
```{r edwSQL_function, eval = FALSE, echo = TRUE}
edwSQL <- function (sql="SELECT TOP 1000 * FROM Event_Cath", resource = "Apollo", file=TRUE, ...) {
    
    # start timer
    start_time <- Sys.time()
    
    # build the connection string
    conn <- odbcDriverConnect(connection_string(resource, database))

    # read the .sql file 
    if (file) {
        sql <- readLines(sql, warn = FALSE)
    }
    
    # and clean up any comments, carriage returns
    sql <- gsub("--.*", "", sql)
    sql <- paste(sql, collapse = " ")

    # send query and close the connection
    queryResult <- sqlQuery(conn, sql, stringsAsFactors = FALSE)
    odbcClose(conn)
    
    # build the function results
    elapsed_seconds <- as.numeric(difftime(Sys.time(), start_time,
                                           units = "secs"))
    status_message <- paste0(
        format(nrow(queryResult), big.mark = ",", 
               scientific = FALSE, trim = TRUE), 
        " records and ", 
        format(length(queryResult), big.mark = ",",
               scientific = FALSE, trim = TRUE), 
        " columns were read from ", 
        resource, " in ",  
        round(elapsed_seconds, 2), " seconds.")
    
    results <- list(
        data = queryResult, 
        fields = names(queryResult),
        elapsed_seconds = elapsed_seconds,
        status_message = status_message))
   
 results
}
```


## connection_string()
```{r connection_string_function, eval = FALSE, echo = TRUE}
connection_string <- function (resource, database=NULL, uid=getOption("Apollo_uid"), pwd=getOption("Apollo_pwd")) {
  result <- switch(resource,
                   Trantor = "Driver=SQL Server;Server=EDWDBProd; Database=ProvidenceEpic",
                   Phloston = "Driver=SQL Server;Server=EDWDBDev; Database=ProvidenceEpic",
                   ClinicalAnalytics = "Driver=SQL Server;Server=wn2591\\PremierPRD; Database=ClinicalAnalytics",
                   Apollo = paste0("Driver=SQL Server;Server=wn1444; Database=Apollo_Spokane; uid=", uid, "; pwd=", pwd),
                   Eva = paste0("Driver=SQL Server;Server=wn1444; Database=Testing; uid=", uid, "; pwd=", pwd)
                   )
  return(result)
}
```



## Multiple Datasources

Query multiple data sources, then merge to a final dataset. 


```{r multiple_sources, echo = TRUE, eval = FALSE}
# Dplyr package warrants a dedicated presentation
library(dplyr) 

tbi_population <- edwSQL(sql = "tbi_cases.sql", resource = "ClinicalAnalytics")
picu_cases <- edwSQL(sql = "picu_admissions.sql", resource = "Trantor")

# merge the two datasets using MRN and HAR
tbi_picu <- 
    tbi_population %>%
    left_join(picu_cases, by = c("mrn", "har")) %>%
    mutate(picu = ifelse(is.na(picu), 0, 1)) %>%
    select(facility, age, gender, picu)

```
```{r multiple_results}
library(knitr)

tbi_picu <- data.frame(facility = c("WSH", "WHF", "WSH", "WSH", "..."), 
                       age = c(0, 8, 3, 15, "..."), 
                       gender = c("M", "F", "F", "M", "..."), 
                       picu = c(1, 0, 1, 0, "..."))

kable(tbi_picu)

```



## Parameterized Queries 

Useful for passing query parameters from R to SQL query dynamically

- dates 
- vectors 
- loops of queries (aka. cursors)



## Dates

```{r edwSQL_dates, echo = TRUE, eval = FALSE}
# also another presentation perhaps?
library(infuser) 

# this template could be loaded from a file instead
sql_template <- "SELECT * from Admissions 
WHERE discharge_date between {{start}} AND {{end}}"

start_date <- as.date("2015-01-01")
end_date <- as.date("2015-06-30")

sql <- infuse(sql_template, start = start_date, end = end_date)

mydata <- edwSQL(sql, resource = "Phloston")


```

## Vectors

```{r edwSQL_vectors, echo = TRUE, eval = FALSE}
# replaces the placeholder with a list
sql_template <- "SELECT * from Final_Diagnosis 
WHERE patient_mrn IN ({{mrn}})"

mrn_list <- c("x0001234", "x0004567", "x0008910")
sql <- infuse(sql_template, mrn = mrn_list)

mydata <- edwSQL(sql, resource = "Phloston")


```


## Parameterized query in a loop (cursor)

### Prompt 
Given a list of MRNs and index discharge dates, provide the primary and secondary diagnosis codes for all encounters within 90 days 

```
-- diagnosis.tpl

SELECT
   medical_record as mrn
 , patient_id as encounter_number
 , facility_id
 , icd9_all_code as diagnosis_cd
 , icd9_all_class as diagnosis_flg
FROM
  ClinicalAnalytics.PHC.patient_icd_diagnosis_code_assignments
WHERE medical_record = '{{mrn}}'
AND discharge_date >= '{{dc_date}}' 
AND admit_date <= DATEADD(day, 90, '{{dc_date}}')
AND icd9_all_class IN ('P', 'S')

```

## Parameterized query in a loop (cursor)

```{r dynamic_query, eval = FALSE, echo = TRUE}

# load patient list
cohort <- read_csv("../Data/Raw Data/study_cohort.csv")

# loop through each row and get the diagnosis codes 
# for every encounter within 90 days of the index discharge
diagnosis_data <- data.frame()

for (i in cohort$mrn) {
   mrn <- as.character(i)
   dc_date = as.character(cohort[cohort$mrn = i, "index_dc_date"])
   
   diagnosis <- template_results(template = "diagnosis.tpl", 
                                 mrn = mrn, 
                                 dc_date = dc_date)
   diagnosis_data <- rbind(diagnosis_data, diagnosis) 
}

```

## Summary

- Loading .csv files is faster with `readr` or `data.table` packages
- RODBC is more efficient, can be automated
- Wrapper functions can make RODBC even easier to use



